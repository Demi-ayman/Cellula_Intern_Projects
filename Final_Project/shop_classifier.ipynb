{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMruJuD/1DuKYue8Q2U5zaB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import Needed Modules"],"metadata":{"id":"xAy-zzpE0o9h"}},{"cell_type":"code","source":["from tensorflow_docs.vis import embed\n","from tensorflow import keras\n","from imutils import paths\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import imageio\n","import cv2\n","import os"],"metadata":{"id":"O-AYcs3I1phH","executionInfo":{"status":"ok","timestamp":1727295562020,"user_tz":-180,"elapsed":287,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2E4RalbNVAB","executionInfo":{"status":"ok","timestamp":1727294522627,"user_tz":-180,"elapsed":17880,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"70f97117-a555-44b3-e9b9-33cfcbb105c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"source":["!pip install git+https://github.com/tensorflow/docs\n","import collections\n","\n","import os\n","import cv2\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","import imageio\n","from IPython import display\n","from urllib import request\n","from tensorflow_docs.vis import embed # After installation, this line should work correctly."],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndyNoTw7VtSk","executionInfo":{"status":"ok","timestamp":1727294542817,"user_tz":-180,"elapsed":20195,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"350b5684-b17b-4fe7-ebfb-dc58748cd75c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/tensorflow/docs\n","  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-7hi26v8x\n","  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-7hi26v8x\n","  Resolved https://github.com/tensorflow/docs to commit 98fa05949ba64f95c4df6565ea915a002a240289\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting astor (from tensorflow-docs==2024.7.15.51478)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (1.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (3.1.4)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (5.10.4)\n","Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==2024.7.15.51478) (6.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==2024.7.15.51478) (2.1.5)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (4.23.0)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (5.7.2)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==2024.7.15.51478) (5.7.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.7.15.51478) (0.20.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2024.7.15.51478) (4.3.6)\n","Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Building wheels for collected packages: tensorflow-docs\n","  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-docs: filename=tensorflow_docs-2024.7.15.51478-py3-none-any.whl size=182586 sha256=89b6ee8777ea11b3ff1382916cb94e7391ce61cb3e03fbd297147bff06694444\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rzgj5gvd/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n","Successfully built tensorflow-docs\n","Installing collected packages: astor, tensorflow-docs\n","Successfully installed astor-0.8.1 tensorflow-docs-2024.7.15.51478\n"]}]},{"cell_type":"markdown","source":["Get Data"],"metadata":{"id":"hSVTp05X1LDO"}},{"cell_type":"code","source":["import zipfile\n","\n","def list_files_from_zip(zip_path):\n","    \"\"\"List the files in each class of the dataset given a local ZIP file.\n","\n","    Args:\n","      zip_path: The path to the local ZIP file.\n","\n","    Returns:\n","      List of files in each of the classes.\n","    \"\"\"\n","    files = []\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        for zip_info in zip_ref.infolist():\n","            files.append(zip_info.filename)\n","    return files\n","\n","URL = \"/content/drive/MyDrive/Shop DataSet.zip\"\n","files = list_files_from_zip(URL)\n","\n","files = [f for f in files if f.endswith('.mp4')]\n","\n","files[:10]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtOZugQkVOaL","executionInfo":{"status":"ok","timestamp":1727294546022,"user_tz":-180,"elapsed":615,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"bf75fbba-cbdf-4efb-ea53-6321ee427667"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Shop DataSet/non shop lifters/shop_lifter_n_0.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_0_1.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_1.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_1_1.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_10.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_10_1.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_100.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_100_1.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_101.mp4',\n"," 'Shop DataSet/non shop lifters/shop_lifter_n_101_1.mp4']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import os\n","\n","def get_class(fname):\n","    split_path = os.path.normpath(fname).split(os.sep)\n","    class_name = split_path[-2]\n","\n","    return class_name"],"metadata":{"id":"1rf_Nc5NVZKE","executionInfo":{"status":"ok","timestamp":1727294577559,"user_tz":-180,"elapsed":312,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["NUM_CLASSES = 2\n","def get_files_per_class(files):\n","\n","  files_for_class = collections.defaultdict(list)\n","  for fname in files:\n","    class_name = get_class(fname)\n","    files_for_class[class_name].append(fname)\n","  return files_for_class\n","\n","\n","files_for_class = get_files_per_class(files)\n","classes = list(files_for_class.keys())"],"metadata":{"id":"4Q1Qpv9iVcgz","executionInfo":{"status":"ok","timestamp":1727294582890,"user_tz":-180,"elapsed":304,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print('Num classes:', len(classes))\n","print('Num videos for class[0]:', len(files_for_class[classes[0]]))\n","print('Num videos for class[1]:', len(files_for_class[classes[1]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cj7joMFLV1QM","executionInfo":{"status":"ok","timestamp":1727294592313,"user_tz":-180,"elapsed":313,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"73a29944-abdd-4105-b46f-b3240de82b64"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Num classes: 2\n","Num videos for class[0]: 531\n","Num videos for class[1]: 324\n"]}]},{"cell_type":"code","source":["print(classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v6qSaohCyABv","executionInfo":{"status":"ok","timestamp":1727294616716,"user_tz":-180,"elapsed":312,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"b0527360-2d9c-4045-be3d-c33757a16d9b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['non shop lifters', 'shop lifters']\n"]}]},{"cell_type":"code","source":["files_for_class"],"metadata":{"id":"piqH5PXGV7Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def select_subset_of_classes(files_for_class, classes, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n","\n","    files_split = dict()\n","\n","    for class_name in classes:\n","        class_files = files_for_class[class_name]\n","        num_files = len(class_files)\n","\n","        # Shuffle files to ensure randomness\n","        random.shuffle(class_files)\n","\n","        # Determine the number of files for each split\n","        num_train = int(train_ratio * num_files)\n","        num_val = int(val_ratio * num_files)\n","        num_test = num_files - num_train - num_val  # The remaining files go to test\n","\n","        # Split the files into train, val, and test sets\n","        train_files = class_files[:num_train]\n","        val_files = class_files[num_train:num_train + num_val]\n","        test_files = class_files[num_train + num_val:]\n","\n","        # Store the subsets for the current class\n","        files_split[class_name] = {\n","            'train': train_files,\n","            'val': val_files,\n","            'test': test_files\n","        }\n","\n","    return files_split\n"],"metadata":{"id":"e7pxvkRKV8Tt","executionInfo":{"status":"ok","timestamp":1727294648352,"user_tz":-180,"elapsed":317,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["files_split = select_subset_of_classes(files_for_class, classes[:NUM_CLASSES])\n","\n","print(len(files_split['non shop lifters']['train']))\n","print(len(files_split['non shop lifters']['val']))\n","print(len(files_split['non shop lifters']['test']))\n","print(len(files_split['shop lifters']['train']))\n","print(len(files_split['shop lifters']['val']))\n","print(len(files_split['shop lifters']['test']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yO6pB55QWGo8","executionInfo":{"status":"ok","timestamp":1727295060240,"user_tz":-180,"elapsed":400,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"b0c0cbfb-6a82-45ce-a62f-f744c87dd05d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["424\n","53\n","54\n","259\n","32\n","33\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Create empty DataFrames for each split\n","train_df = pd.DataFrame()\n","val_df = pd.DataFrame()\n","test_df = pd.DataFrame()\n","\n","# Iterate over classes and splits\n","for class_name, class_data in files_split.items():\n","    for split_name, files in class_data.items():\n","        # Create a DataFrame for the current split\n","        split_df = pd.DataFrame({'filename': files, 'class': class_name})\n","\n","        # Append to the corresponding DataFrame\n","        if split_name == 'train':\n","            train_df = pd.concat([train_df, split_df], ignore_index=True)\n","        elif split_name == 'val':\n","            val_df = pd.concat([val_df, split_df], ignore_index=True)\n","        elif split_name == 'test':\n","            test_df = pd.concat([test_df, split_df], ignore_index=True)\n","\n","# Print the DataFrames\n","print(train_df)\n","print(val_df)\n","print(test_df)"],"metadata":{"id":"-jYVpMk50OG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(f\"Total videos for training: {len(train_df)}\")\n","print(f\"Total videos for testing: {len(test_df)}\")\n","\n","train_df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"4qRXdtLY0Xxm","executionInfo":{"status":"ok","timestamp":1727295240501,"user_tz":-180,"elapsed":325,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"218b679a-22aa-480f-83b8-309c42014949"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Total videos for training: 683\n","Total videos for testing: 87\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              filename             class\n","589     Shop DataSet/shop lifters/videmmmmmmsss_86.mp4      shop lifters\n","46   Shop DataSet/non shop lifters/shop_lifter_n_18...  non shop lifters\n","387  Shop DataSet/non shop lifters/shop_lifter_n_18...  non shop lifters\n","74   Shop DataSet/non shop lifters/shop_lifter_n_12...  non shop lifters\n","573       Shop DataSet/shop lifters/shop_lifter_97.mp4      shop lifters\n","228  Shop DataSet/non shop lifters/shop_lifter_n_11...  non shop lifters\n","388   Shop DataSet/non shop lifters/videppppsss_18.mp4  non shop lifters\n","376  Shop DataSet/non shop lifters/shop_lifter_n_92...  non shop lifters\n","131  Shop DataSet/non shop lifters/shop_lifter_n_15...  non shop lifters\n","15   Shop DataSet/non shop lifters/shop_lifter_n_51...  non shop lifters"],"text/html":["\n","  <div id=\"df-4ae0c96e-3a72-4d2e-9a63-b2d30ae16e46\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>589</th>\n","      <td>Shop DataSet/shop lifters/videmmmmmmsss_86.mp4</td>\n","      <td>shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_18...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>387</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_18...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_12...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>Shop DataSet/shop lifters/shop_lifter_97.mp4</td>\n","      <td>shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_11...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>Shop DataSet/non shop lifters/videppppsss_18.mp4</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>376</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_92...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_15...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Shop DataSet/non shop lifters/shop_lifter_n_51...</td>\n","      <td>non shop lifters</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ae0c96e-3a72-4d2e-9a63-b2d30ae16e46')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4ae0c96e-3a72-4d2e-9a63-b2d30ae16e46 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4ae0c96e-3a72-4d2e-9a63-b2d30ae16e46');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f6d9e6fd-86f8-4e47-9091-495962ef3819\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6d9e6fd-86f8-4e47-9091-495962ef3819')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f6d9e6fd-86f8-4e47-9091-495962ef3819 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"train_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Shop DataSet/non shop lifters/shop_lifter_n_155_1.mp4\",\n          \"Shop DataSet/non shop lifters/shop_lifter_n_189.mp4\",\n          \"Shop DataSet/non shop lifters/shop_lifter_n_110_1.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non shop lifters\",\n          \"shop lifters\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Set Hyperparameters"],"metadata":{"id":"T3LYu9nq1RG-"}},{"cell_type":"code","source":["IMG_SIZE = 224\n","BATCH_SIZE = 64\n","EPOCHS = 100\n","\n","MAX_SEQ_LENGTH = 5\n","NUM_FEATURES = 2048"],"metadata":{"id":"E9RBseS_0dS2","executionInfo":{"status":"ok","timestamp":1727295478906,"user_tz":-180,"elapsed":332,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Create Helper Functions"],"metadata":{"id":"xSew5Ujc1Xwf"}},{"cell_type":"code","source":["def crop_center_square(frame):\n","    y, x = frame.shape[0:2]\n","    min_dim = min(y, x)\n","    start_x = (x // 2) - (min_dim // 2)\n","    start_y = (y // 2) - (min_dim // 2)\n","    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n","\n","\n","def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n","    cap = cv2.VideoCapture(path)\n","    frames = []\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = crop_center_square(frame)\n","            frame = cv2.resize(frame, resize)\n","            frame = frame[:, :, [2, 1, 0]]\n","            frames.append(frame)\n","\n","            if len(frames) == max_frames:\n","                break\n","    finally:\n","        cap.release()\n","    return np.array(frames)"],"metadata":{"id":"ceM_R_JD0l1_","executionInfo":{"status":"ok","timestamp":1727295522151,"user_tz":-180,"elapsed":305,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def build_feature_extractor():\n","    feature_extractor = keras.applications.resnet50.ResNet50(\n","        weights=\"imagenet\",\n","        include_top=False,\n","        pooling=\"avg\",\n","        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","    )\n","    preprocess_input = keras.applications.inception_v3.preprocess_input\n","\n","    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n","    preprocessed = preprocess_input(inputs)\n","\n","    outputs = feature_extractor(preprocessed)\n","    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n","\n","\n","feature_extractor = build_feature_extractor()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uysyhBdm1guw","executionInfo":{"status":"ok","timestamp":1727295570995,"user_tz":-180,"elapsed":3877,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"c87b83be-3a3c-48f3-e532-b674ab019515"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"class\"]))\n","\n","print(label_processor.get_vocabulary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODxpY3v21sw_","executionInfo":{"status":"ok","timestamp":1727295633778,"user_tz":-180,"elapsed":384,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"5a58c757-1ad6-4555-d4af-88562eb6a2e5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["['non shop lifters', 'shop lifters']\n"]}]},{"cell_type":"code","source":["os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 2 to filter out INFO and WARNING, 3 to filter out INFO, WARNING, and ERROR"],"metadata":{"id":"s2Phrlhl171N","executionInfo":{"status":"ok","timestamp":1727295659320,"user_tz":-180,"elapsed":303,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import contextlib\n","import tqdm\n","\n","@contextlib.contextmanager\n","def suppress_stdout():\n","    with open(os.devnull, 'w') as devnull:\n","        old_stdout = sys.stdout\n","        sys.stdout = devnull\n","        try:\n","            yield\n","        finally:\n","            sys.stdout = old_stdout"],"metadata":{"id":"WyP6sbaU2CTv","executionInfo":{"status":"ok","timestamp":1727295674367,"user_tz":-180,"elapsed":303,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def prepare_all_videos(df, root_dir):\n","    num_samples = len(df)\n","    video_paths = df[\"filename\"].values.tolist()\n","    labels = df[\"class\"].values\n","    labels = label_processor(labels[..., None]).numpy()\n","\n","    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n","    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n","    # masked with padding or not.\n","    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n","    frame_features = np.zeros(\n","        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","    )\n","\n","    # For each video.\n","    for idx, path in tqdm.tqdm(enumerate(video_paths), total=len(video_paths)):\n","        # Gather all its frames and add a batch dimension.\n","#         frames = load_video(os.path.join(root_dir, path))\n","        frames = load_video( path)\n","\n","        frames = frames[None, ...]\n","\n","        # Initialize placeholders to store the masks and features of the current video.\n","        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n","        temp_frame_features = np.zeros(\n","            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n","        )\n","\n","        # Extract features from the frames of the current video.\n","        for i, batch in enumerate(frames):\n","            video_length = batch.shape[0]\n","            length = min(MAX_SEQ_LENGTH, video_length)\n","            for j in range(length):\n","                with suppress_stdout():\n","\n","                    temp_frame_features[i, j, :] = feature_extractor.predict(\n","                        batch[None, j, :]\n","                    )\n","            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","\n","        frame_features[idx,] = temp_frame_features.squeeze()\n","        frame_masks[idx,] = temp_frame_mask.squeeze()\n","\n","    return (frame_features, frame_masks), labels\n","\n","\n","train_data, train_labels = prepare_all_videos(train_df, \"train\")\n","test_data, test_labels = prepare_all_videos(test_df, \"test\")\n","\n","print(f\"Frame features in train set: {train_data[0].shape}\")\n","print(f\"Frame masks in train set: {train_data[1].shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pBeB0DU2FzW","executionInfo":{"status":"ok","timestamp":1727295731663,"user_tz":-180,"elapsed":514,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"6c0b61a9-5bfe-45e6-9c12-1c0b85a7db42"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 683/683 [00:00<00:00, 7354.29it/s]\n","100%|██████████| 87/87 [00:00<00:00, 11335.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Frame features in train set: (683, 5, 2048)\n","Frame masks in train set: (683, 5)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Utility for our sequence model.\n","def get_sequence_model():\n","    class_vocab = label_processor.get_vocabulary()\n","\n","    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n","    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n","\n","    # Refer to the following tutorial to understand the significance of using `mask`:\n","    # https://keras.io/api/layers/recurrent_layers/gru/\n","    x = keras.layers.GRU(16, return_sequences=True)(\n","        frame_features_input, mask=mask_input\n","    )\n","    x = keras.layers.GRU(8)(x)\n","    x = keras.layers.Dropout(0.4)(x)\n","    x = keras.layers.Dense(8, activation=\"relu\")(x)\n","    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n","\n","    rnn_model = keras.Model([frame_features_input, mask_input], output)\n","\n","    rnn_model.compile(\n","        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n","    )\n","    return rnn_model\n","\n","\n","# Utility for running experiments.\n","def run_experiment():\n","    #filepath = \"/tmp/video_classifier\"\n","    #checkpoint = keras.callbacks.ModelCheckpoint(\n","    #    filepath, save_weights_only=True, save_best_only=True, verbose=1\n","    #)\n","\n","    seq_model = get_sequence_model()\n","    history = seq_model.fit(\n","        [train_data[0], train_data[1]],\n","        train_labels,\n","        validation_split=0.3,\n","        epochs=EPOCHS,\n","        #callbacks=[checkpoint],\n","    )\n","\n","    #seq_model.load_weights(filepath)\n","    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","    return history, seq_model\n","\n","\n","_, sequence_model = run_experiment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ThHn8T62UOG","executionInfo":{"status":"ok","timestamp":1727296065243,"user_tz":-180,"elapsed":53315,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"5e0497df-9291-477a-c02a-f79d0c38ded6"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.8859 - loss: 0.6903 - val_accuracy: 0.0000e+00 - val_loss: 0.7081\n","Epoch 2/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8858 - loss: 0.6790 - val_accuracy: 0.0000e+00 - val_loss: 0.7233\n","Epoch 3/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8887 - loss: 0.6678 - val_accuracy: 0.0000e+00 - val_loss: 0.7385\n","Epoch 4/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9059 - loss: 0.6555 - val_accuracy: 0.0000e+00 - val_loss: 0.7537\n","Epoch 5/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9011 - loss: 0.6451 - val_accuracy: 0.0000e+00 - val_loss: 0.7691\n","Epoch 6/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8929 - loss: 0.6358 - val_accuracy: 0.0000e+00 - val_loss: 0.7844\n","Epoch 7/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8882 - loss: 0.6268 - val_accuracy: 0.0000e+00 - val_loss: 0.7996\n","Epoch 8/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8826 - loss: 0.6184 - val_accuracy: 0.0000e+00 - val_loss: 0.8149\n","Epoch 9/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9022 - loss: 0.6049 - val_accuracy: 0.0000e+00 - val_loss: 0.8305\n","Epoch 10/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8954 - loss: 0.5973 - val_accuracy: 0.0000e+00 - val_loss: 0.8459\n","Epoch 11/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8837 - loss: 0.5917 - val_accuracy: 0.0000e+00 - val_loss: 0.8613\n","Epoch 12/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8807 - loss: 0.5845 - val_accuracy: 0.0000e+00 - val_loss: 0.8767\n","Epoch 13/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9019 - loss: 0.5694 - val_accuracy: 0.0000e+00 - val_loss: 0.8923\n","Epoch 14/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8882 - loss: 0.5661 - val_accuracy: 0.0000e+00 - val_loss: 0.9078\n","Epoch 15/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8762 - loss: 0.5632 - val_accuracy: 0.0000e+00 - val_loss: 0.9231\n","Epoch 16/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8797 - loss: 0.5546 - val_accuracy: 0.0000e+00 - val_loss: 0.9386\n","Epoch 17/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8904 - loss: 0.5430 - val_accuracy: 0.0000e+00 - val_loss: 0.9541\n","Epoch 18/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9123 - loss: 0.5258 - val_accuracy: 0.0000e+00 - val_loss: 0.9697\n","Epoch 19/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8866 - loss: 0.5312 - val_accuracy: 0.0000e+00 - val_loss: 0.9846\n","Epoch 20/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9011 - loss: 0.5173 - val_accuracy: 0.0000e+00 - val_loss: 1.0003\n","Epoch 21/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8776 - loss: 0.5233 - val_accuracy: 0.0000e+00 - val_loss: 1.0153\n","Epoch 22/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8742 - loss: 0.5196 - val_accuracy: 0.0000e+00 - val_loss: 1.0303\n","Epoch 23/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8964 - loss: 0.5010 - val_accuracy: 0.0000e+00 - val_loss: 1.0458\n","Epoch 24/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8735 - loss: 0.5092 - val_accuracy: 0.0000e+00 - val_loss: 1.0606\n","Epoch 25/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9073 - loss: 0.4826 - val_accuracy: 0.0000e+00 - val_loss: 1.0760\n","Epoch 26/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9126 - loss: 0.4733 - val_accuracy: 0.0000e+00 - val_loss: 1.0911\n","Epoch 27/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9001 - loss: 0.4762 - val_accuracy: 0.0000e+00 - val_loss: 1.1056\n","Epoch 28/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8786 - loss: 0.4862 - val_accuracy: 0.0000e+00 - val_loss: 1.1202\n","Epoch 29/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8849 - loss: 0.4772 - val_accuracy: 0.0000e+00 - val_loss: 1.1351\n","Epoch 30/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8987 - loss: 0.4624 - val_accuracy: 0.0000e+00 - val_loss: 1.1495\n","Epoch 31/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8833 - loss: 0.4696 - val_accuracy: 0.0000e+00 - val_loss: 1.1640\n","Epoch 32/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8818 - loss: 0.4666 - val_accuracy: 0.0000e+00 - val_loss: 1.1784\n","Epoch 33/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8897 - loss: 0.4562 - val_accuracy: 0.0000e+00 - val_loss: 1.1929\n","Epoch 34/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8955 - loss: 0.4474 - val_accuracy: 0.0000e+00 - val_loss: 1.2073\n","Epoch 35/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9001 - loss: 0.4395 - val_accuracy: 0.0000e+00 - val_loss: 1.2214\n","Epoch 36/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8792 - loss: 0.4538 - val_accuracy: 0.0000e+00 - val_loss: 1.2351\n","Epoch 37/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8526 - loss: 0.4741 - val_accuracy: 0.0000e+00 - val_loss: 1.2487\n","Epoch 38/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8833 - loss: 0.4436 - val_accuracy: 0.0000e+00 - val_loss: 1.2628\n","Epoch 39/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9049 - loss: 0.4202 - val_accuracy: 0.0000e+00 - val_loss: 1.2768\n","Epoch 40/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8878 - loss: 0.4328 - val_accuracy: 0.0000e+00 - val_loss: 1.2905\n","Epoch 41/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8943 - loss: 0.4234 - val_accuracy: 0.0000e+00 - val_loss: 1.3041\n","Epoch 42/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8666 - loss: 0.4477 - val_accuracy: 0.0000e+00 - val_loss: 1.3170\n","Epoch 43/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8792 - loss: 0.4325 - val_accuracy: 0.0000e+00 - val_loss: 1.3307\n","Epoch 44/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8701 - loss: 0.4393 - val_accuracy: 0.0000e+00 - val_loss: 1.3436\n","Epoch 45/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8755 - loss: 0.4314 - val_accuracy: 0.0000e+00 - val_loss: 1.3565\n","Epoch 46/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8863 - loss: 0.4176 - val_accuracy: 0.0000e+00 - val_loss: 1.3696\n","Epoch 47/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9006 - loss: 0.3997 - val_accuracy: 0.0000e+00 - val_loss: 1.3830\n","Epoch 48/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8947 - loss: 0.4035 - val_accuracy: 0.0000e+00 - val_loss: 1.3953\n","Epoch 49/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8902 - loss: 0.4061 - val_accuracy: 0.0000e+00 - val_loss: 1.4078\n","Epoch 50/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8908 - loss: 0.4032 - val_accuracy: 0.0000e+00 - val_loss: 1.4203\n","Epoch 51/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8905 - loss: 0.4013 - val_accuracy: 0.0000e+00 - val_loss: 1.4327\n","Epoch 52/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8815 - loss: 0.4096 - val_accuracy: 0.0000e+00 - val_loss: 1.4449\n","Epoch 53/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8905 - loss: 0.3972 - val_accuracy: 0.0000e+00 - val_loss: 1.4572\n","Epoch 54/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8955 - loss: 0.3892 - val_accuracy: 0.0000e+00 - val_loss: 1.4693\n","Epoch 55/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9015 - loss: 0.3800 - val_accuracy: 0.0000e+00 - val_loss: 1.4813\n","Epoch 56/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8725 - loss: 0.4135 - val_accuracy: 0.0000e+00 - val_loss: 1.4923\n","Epoch 57/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8858 - loss: 0.3956 - val_accuracy: 0.0000e+00 - val_loss: 1.5039\n","Epoch 58/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8826 - loss: 0.3981 - val_accuracy: 0.0000e+00 - val_loss: 1.5155\n","Epoch 59/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8893 - loss: 0.3880 - val_accuracy: 0.0000e+00 - val_loss: 1.5271\n","Epoch 60/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.4194 - val_accuracy: 0.0000e+00 - val_loss: 1.5375\n","Epoch 61/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8976 - loss: 0.3742 - val_accuracy: 0.0000e+00 - val_loss: 1.5495\n","Epoch 62/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8953 - loss: 0.3755 - val_accuracy: 0.0000e+00 - val_loss: 1.5607\n","Epoch 63/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8818 - loss: 0.3921 - val_accuracy: 0.0000e+00 - val_loss: 1.5708\n","Epoch 64/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8808 - loss: 0.3922 - val_accuracy: 0.0000e+00 - val_loss: 1.5815\n","Epoch 65/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9025 - loss: 0.3617 - val_accuracy: 0.0000e+00 - val_loss: 1.5927\n","Epoch 66/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8991 - loss: 0.3648 - val_accuracy: 0.0000e+00 - val_loss: 1.6030\n","Epoch 67/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8963 - loss: 0.3675 - val_accuracy: 0.0000e+00 - val_loss: 1.6133\n","Epoch 68/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8785 - loss: 0.3909 - val_accuracy: 0.0000e+00 - val_loss: 1.6234\n","Epoch 69/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8921 - loss: 0.3708 - val_accuracy: 0.0000e+00 - val_loss: 1.6336\n","Epoch 70/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8889 - loss: 0.3744 - val_accuracy: 0.0000e+00 - val_loss: 1.6432\n","Epoch 71/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8837 - loss: 0.3808 - val_accuracy: 0.0000e+00 - val_loss: 1.6530\n","Epoch 72/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8801 - loss: 0.3850 - val_accuracy: 0.0000e+00 - val_loss: 1.6625\n","Epoch 73/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8891 - loss: 0.3711 - val_accuracy: 0.0000e+00 - val_loss: 1.6725\n","Epoch 74/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9024 - loss: 0.3506 - val_accuracy: 0.0000e+00 - val_loss: 1.6825\n","Epoch 75/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8857 - loss: 0.3743 - val_accuracy: 0.0000e+00 - val_loss: 1.6905\n","Epoch 76/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8776 - loss: 0.3856 - val_accuracy: 0.0000e+00 - val_loss: 1.6998\n","Epoch 77/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8990 - loss: 0.3528 - val_accuracy: 0.0000e+00 - val_loss: 1.7100\n","Epoch 78/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8945 - loss: 0.3588 - val_accuracy: 0.0000e+00 - val_loss: 1.7183\n","Epoch 79/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8700 - loss: 0.3952 - val_accuracy: 0.0000e+00 - val_loss: 1.7267\n","Epoch 80/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8978 - loss: 0.3522 - val_accuracy: 0.0000e+00 - val_loss: 1.7363\n","Epoch 81/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8845 - loss: 0.3718 - val_accuracy: 0.0000e+00 - val_loss: 1.7445\n","Epoch 82/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8856 - loss: 0.3696 - val_accuracy: 0.0000e+00 - val_loss: 1.7530\n","Epoch 83/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8828 - loss: 0.3732 - val_accuracy: 0.0000e+00 - val_loss: 1.7611\n","Epoch 84/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9008 - loss: 0.3443 - val_accuracy: 0.0000e+00 - val_loss: 1.7699\n","Epoch 85/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8968 - loss: 0.3501 - val_accuracy: 0.0000e+00 - val_loss: 1.7780\n","Epoch 86/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8908 - loss: 0.3589 - val_accuracy: 0.0000e+00 - val_loss: 1.7856\n","Epoch 87/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8967 - loss: 0.3489 - val_accuracy: 0.0000e+00 - val_loss: 1.7939\n","Epoch 88/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9086 - loss: 0.3291 - val_accuracy: 0.0000e+00 - val_loss: 1.8021\n","Epoch 89/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8982 - loss: 0.3452 - val_accuracy: 0.0000e+00 - val_loss: 1.8097\n","Epoch 90/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8816 - loss: 0.3717 - val_accuracy: 0.0000e+00 - val_loss: 1.8164\n","Epoch 91/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8816 - loss: 0.3715 - val_accuracy: 0.0000e+00 - val_loss: 1.8237\n","Epoch 92/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8816 - loss: 0.3711 - val_accuracy: 0.0000e+00 - val_loss: 1.8305\n","Epoch 93/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8869 - loss: 0.3619 - val_accuracy: 0.0000e+00 - val_loss: 1.8385\n","Epoch 94/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8860 - loss: 0.3630 - val_accuracy: 0.0000e+00 - val_loss: 1.8459\n","Epoch 95/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8672 - loss: 0.3941 - val_accuracy: 0.0000e+00 - val_loss: 1.8532\n","Epoch 96/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8895 - loss: 0.3563 - val_accuracy: 0.0000e+00 - val_loss: 1.8605\n","Epoch 97/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8806 - loss: 0.3709 - val_accuracy: 0.0000e+00 - val_loss: 1.8665\n","Epoch 98/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8899 - loss: 0.3549 - val_accuracy: 0.0000e+00 - val_loss: 1.8735\n","Epoch 99/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8810 - loss: 0.3698 - val_accuracy: 0.0000e+00 - val_loss: 1.8802\n","Epoch 100/100\n","\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8886 - loss: 0.3565 - val_accuracy: 0.0000e+00 - val_loss: 1.8865\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.5583 \n","Test accuracy: 62.07%\n"]}]},{"cell_type":"code","source":["def prepare_single_video(frames):\n","    frames = frames[None, ...]\n","    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n","    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n","\n","    for i, batch in enumerate(frames):\n","        video_length = batch.shape[0]\n","        length = min(MAX_SEQ_LENGTH, video_length)\n","        for j in range(length):\n","            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n","        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n","\n","    return frame_features, frame_mask\n","\n","\n","def sequence_prediction(path):\n","    class_vocab = label_processor.get_vocabulary()\n","\n","    frames = load_video(os.path.join(\"test\", path))\n","    frame_features, frame_mask = prepare_single_video(frames)\n","    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n","\n","    for i in np.argsort(probabilities)[::-1]:\n","        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n","    return frames\n","\n","\n","# This utility is for visualization.\n","# Referenced from:\n","# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n","def to_gif(images):\n","    converted_images = images.astype(np.uint8)\n","    imageio.mimsave(\"animation.gif\", converted_images, duration=100)\n","    return embed.embed_file(\"animation.gif\")"],"metadata":{"id":"Hzjt7AjG3ml_","executionInfo":{"status":"ok","timestamp":1727296137890,"user_tz":-180,"elapsed":300,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Test Video"],"metadata":{"id":"_8RwYgvq38Pf"}},{"cell_type":"code","source":["test_video = np.random.choice(test_df[\"filename\"].values.tolist())\n","print(f\"Test video path: {test_video}\")\n","test_frames = sequence_prediction(test_video)\n","to_gif(test_frames[:MAX_SEQ_LENGTH])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"P6Q7AUdF33W2","executionInfo":{"status":"error","timestamp":1727296194612,"user_tz":-180,"elapsed":963,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"84d7bfd8-341f-40ae-8525-a2a5c48adbfa"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Test video path: Shop DataSet/shop lifters/videppppsss_6.mp4\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n","  non shop lifters: 84.84%\n","  shop lifters: 15.16%\n"]},{"output_type":"error","ename":"ValueError","evalue":"Image data must be a sequence of ndimages.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f2004e1c2611>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test video path: {test_video}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mto_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-34a414a8f930>\u001b[0m in \u001b[0;36mto_gif\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mconverted_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"animation.gif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"animation.gif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data must be a sequence of ndimages.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0mimopen_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecypher_format_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Image data must be a sequence of ndimages."]}]},{"cell_type":"code","source":["test_frames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LymW_xet4LS_","executionInfo":{"status":"ok","timestamp":1727296225765,"user_tz":-180,"elapsed":295,"user":{"displayName":"Demiana Ayman","userId":"15183520974475801206"}},"outputId":"a3096624-91f3-41e2-cc8e-eda5ace4b9de"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([], dtype=float64)"]},"metadata":{},"execution_count":31}]}]}